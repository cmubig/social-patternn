{
    "base_config": "./social-patternn/config/mcts_max8/base_config.json",
	
	"trainer": "vrnn",
	"coord": "abs",

	"gpu_id": 0,
	"use_cpu": true,
	
	"training_details": {
		"num_samples": 20,
		"load_model": false,
		"max_agents": 8,
		"eval_ckpt": false,
		"ckpt_name": "ckpt_0.pth",
		"ckpt_freq": 100,
		"batch_size": 1,
		"eval_batch_size": 8,
		"num_epoch": 500,
		"num_iter": -1,
		"eval_num_iter": -1,
		"test_num_iter": -1,
		"lr": 1e-3,
		"update_lr": false,
		"start": 0,
		"patience": 100,
		"warmup": false,
		"warmup_epochs": 50,
		"gradient_clip": 10,
		"seed": 1
	},
	
	"model_design": {
		"dim": 3,
		"feat_enc_x": {
			"in_size": 3,
			"hidden_size": [96],
			"out_size": 96,
			"dropout": 0.0,
			"layer_norm": false
		},
		"encoder": {
			"in_size": 192,
			"hidden_size": [96],
			"out_size": 48,
			"dropout": 0.0,
			"layer_norm": false
		},
		"prior": {
			"in_size": 96,
			"hidden_size": [96],
			"out_size": 48,
			"dropout": 0.0,
			"layer_norm": false
		},
		"feat_enc_z": {
			"in_size": 24,
			"hidden_size": [96],
			"out_size": 96,
			"dropout": 0.0,
			"layer_norm": false
		},
		"decoder": {
			"in_size": 192,
			"hidden_size": [96],
			"out_size": 6,
			"dropout": 0.0,
			"layer_norm": false
		},
		"rnn": {
			"in_size": 192,
			"hidden_size": 96,
			"num_layers": 2
		}
	}
}
