{
    "base_config": "./config/mcts/base_config.json",
	
	"exp_tag": "",
	"trainer": "socpatternn-mlp",
	"coord": "abs",

	"gpu_id": 0,
	"use_cpu": true,
	
	"training_details": {
		"num_samples": 20,
		"load_model": false,
		"max_agents": 8,
		"eval_ckpt": false,
		"ckpt_name": "ckpt_0.pth",
		"ckpt_freq": 100,
		"batch_size": 1,
		"eval_batch_size": 8,
		"num_epoch": 1000,
		"num_iter": -1,
		"eval_num_iter": -1,
		"test_num_iter": -1,
		"lr": 1e-3,
		"update_lr": false,
		"start": 0,
		"patience": 100,
		"warmup": false,
		"warmup_epochs": 50,
		"gradient_clip": 10,
		"seed": 1
	},
	
	"model_design": {
		"dim": 3,
		"scale": 1.0, 
		"feat_enc_x": {
			"in_size": 3,
			"hidden_size": [96],
			"out_size": 96,
			"dropout": 0.0,
			"layer_norm": false
		},
		"encoder": {
			"in_size": 288,
			"hidden_size": [96],
			"out_size": 48,
			"dropout": 0.0,
			"layer_norm": false
		},
		"prior": {
			"in_size": 96,
			"hidden_size": [96],
			"out_size": 48,
			"dropout": 0.0,
			"layer_norm": false
		},
		"feat_enc_z": {
			"in_size": 24,
			"hidden_size": [96],
			"out_size": 96,
			"dropout": 0.0,
			"layer_norm": false
		},
		"decoder": {
			"in_size": 384,
			"hidden_size": [96],
			"out_size": 6,
			"dropout": 0.0,
			"layer_norm": false
		},
		"rnn": {
			"in_size": 192,
			"hidden_size": 96,
			"num_layers": 2
		},
		"pattern_net": {
			"pat_len": 7,
			"feat_pat": {
				"in_size": -1,
                "hidden_size": [96],
                "out_size": 96,
                "dropout": 0.0,
                "layer_norm": false
			},
			"dec_pat": {
				"in_size": 123,
                "hidden_size": [96],
                "out_size": -1,
                "dropout": 0.0,
                "layer_norm": false
			}
		},
		"interaction_net": {
			"type": "mlp",
			"k_nearest": 2,
            "feat_soc": {
                "in_size": 6,
                "hidden_size": [96],
                "out_size": 96,
                "dropout": 0.0,
                "layer_norm": false
            }
		}
	}
}
